# Large Language Model in Bioinformatics and Healthcare
dipresentasikan oleh prof. alhadi bustamam, ph.d., dan Dr. risman adnan.


## Intoduction

Large Language Model(LLMs) adalah model kecerdasan buatan yang dirancang untuk memahami dan menghasilkan bahasa manusia. Model ini memiliki kemampuan untuk memahami, menghasilkan, dan mengubah bahasa manusia karena dilatih pada jumlah data teks yang besar. Model ini dibangun menggunakan "deep learning" dan secara khusus termasuk dalam kategori model "transformer". Salah satu versi model ini yang paling terkenal adalah seri GPT (Generative Pre-trained Transformer), yang mencakup GPT. 3.5, di mana ChatGPT dibangun.

## What are Large Language Models?

Large language model adalah tipe model kecerdasan buatan yang dilatih pada sejumlah besar data untuk menghasilkan teks yang mirip dengan manusia. Model ini ditandai dengan jumlah parameter yang besar, yang dapat berkisar dari 28 hingga 1378, dan kemampuannya untuk mewakili ketergantungan jangka panjang dalam teks menggunakan arsitektur Transformer.


## Cara Kerja Large Language Model

LLMs dibuat berdasarkan arsitektur Transformer, yang sangat baik dalam menangkap informasi kontekstual dari teks.

Mereka terdiri dari beberapa lapisan mekanisme perhatian dan jaringan feedfonward, memungkinkan mereka untuk memproses dan generale teks dengan kesadaran konteks.

Model ini belajar untuk memprediksi kata berikutnya dalam kalimat dengan mempertimbangkan kata-kata sebelumnya, memungkinkan mereka untuk menghasilkan kalimat yang koheren.


## Aplikasi Large Laguage Models

- Pembuatan Teks: Large Language Models (LLMs) mampu menghasilkan teks yang mirip dengan manusia, sehingga berguna untuk tugas-tugas seperti pembuatan konten otomatis, chatbot, dan bahkan penulisan kreatif. Dengan dilatih pada jumlah data teks yang besar, LLMs dapat belajar untuk menghasilkan teks yang koheren dan relevan secara kontekstual.

- Terjemahan: LLMs dapat dilatih untuk menerjemahkan teks dari satu bahasa ke bahasa lain, sehingga berguna untuk tugas-tugas seperti pembelajaran bahasa, komunikasi lintas budaya, dan bisnis internasional. Dengan belajar untuk memahami nuansa bahasa yang berbeda, LLMs dapat menghasilkan terjemahan yang akurat dan terdengar alami.

- Kecerdasan Buatan Percakapan: LLMs dapat digunakan untuk membuat chatbot dan aplikasi kecerdasan buatan percakapan lainnya. Dengan dilatih pada jumlah besar data percakapan, LLMs dapat belajar untuk memahami dan merespons masukan bahasa alami, sehingga berguna untuk tugas-tugas seperti layanan pelanggan, asisten pribadi, dan lain-lain.
- Pembuatan Konten: LLMs dapat digunakan untuk menghasilkan berbagai jenis konten, termasuk artikel, posting blog, dan media sosial. Dengan dilatih pada jumlah besar data teks, LLMs dapat belajar untuk menghasilkan konten yang relevan, menarik, dan disesuaikan dengan audiens tertentu.

- Jawaban Pertanyaan: LLMs dapat dilatih untuk menjawab pertanyaan berdasarkan konteks yang diberikan, sehingga berguna untuk tugas-tugas seperti dukungan pelanggan, pendidikan, dan penelitian. Dengan belajar untuk memahami konteks pertanyaan, LLMs dapat memberikan jawaban yang akurat dan relevan untuk berbagai jenis pertanyaan.

- Pemahaman Bahasa Alami (NLU): LLMs dapat digunakan untuk memahami makna teks, sehingga berguna untuk tugas-tugas seperti analisis sentimen, pemodelan topik, dan lain-lain. Dengan dilatih pada jumlah besar data teks, LLMs dapat belajar untuk memahami nuansa bahasa, sehingga dapat melakukan berbagai tugas NLU.

- Pemulihan Informasi: LLMs dapat digunakan untuk mengambil informasi dari jumlah besar teks, sehingga berguna untuk tugas-tugas seperti mesin pencari, sistem rekomendasi, dan lain-lain. Dengan belajar untuk memahami konteks dari sebuah permintaan, LLMs dapat memberikan hasil yang akurat dan relevan untuk berbagai jenis permintaan.

- Personalisasi Konten: LLMs dapat digunakan untuk mempersonalisasi konten untuk audiens tertentu, sehingga berguna untuk tugas-tugas seperti pemasaran, periklanan, dan lain-lain. Dengan belajar untuk memahami preferensi dari audiens yang berbeda, LLMs dapat menghasilkan konten yang disesuaikan dengan kebutuhan dan minat mereka.

- Pembuatan Kode: LLMs dapat digunakan untuk menghasilkan kode untuk berbagai aplikasi, sehingga berguna untuk tugas-tugas seperti pengembangan perangkat lunak, ilmu data, dan lain-lain. Dengan dilatih pada jumlah besar kode, LLMs dapat belajar untuk menghasilkan kode yang akurat dan efisien, sehingga dapat melakukan berbagai tugas.

- Legal dan Kepatuhan: LLMs dapat digunakan untuk mengotomatisasi tugas-tugas hukum dan kepatuhan, sehingga berguna untuk tugas-tugas seperti tinjauan kontrak, kewajiban dilakukan, dan lain-lain. Dengan belajar untuk memahami nuansa bahasa hukum, LLMs dapat memberikan hasil yang akurat dan relevan untuk berbagai jenis tugas.

- Aplikasi Medis dan Kesehatan: LLMs dapat digunakan untuk mengotomatisasi tugas-tugas medis dan kesehatan, sehingga berguna untuk tugas-tugas seperti diagnosis, pengobatan, dan lain-lain. Dengan belajar untuk memahami nuansa bahasa medis, LLMs dapat memberikan hasil yang akurat dan relevan untuk berbagai jenis tugas.


## Sejarah Singkat Large Language Models

Perjalanan dari Jaringan Saraf Tiruan dan Pemrosesan Bahasa Alami (NLP) dimulai pada tahun 1950-an. Era ini menandai awal dari teknologi-teknologi ini, membentuk dasar untuk kemajuan di masa depan dalam bidang kecerdasan buatan.

Pada tahun 2000-an, model bahasa statistik menjadi populer. Model-model ini menggunakan metode statistik untuk memprediksi kemungkinan urutan kata, meningkatkan efisiensi dan akurasi terjemahan mesin dan pengenalan ucapan.

Pada tahun 2010-an, Deep Learning mengalami kebangkitan, terutama karena pengembangan AlexNet dan paralelisasi pelatihan pada GPU. Hal ini memungkinkan pelatihan jaringan saraf yang kompleks menjadi lebih cepat dan efisien.

Word Embedding menjadi populer pada tahun 2013 dengan diperkenalkannya Word2Vec dan GloVe. Teknik-teknik ini merepresentasikan kata-kata dalam ruang vektor di mana makna semantik kata-kata ditangkap oleh jarak dan arahnya dari kata-kata lain.

Long Short-Term Memory (LSTM) dan Recurrent Neural Networks (RNN) dikembangkan untuk embedding kata yang terkontekstualisasi dan generasi teks. Model-model ini dapat memahami konteks kata dalam sebuah kalimat dengan mempertimbangkan kata-kata di sekitarnya.

Arsitektur Transformer diperkenalkan pada tahun 2017, menampilkan mekanisme Attention dan Self-Attention untuk menangkap hubungan kontekstual antara kata-kata dalam sebuah kalimat. Arsitektur ini sangat meningkatkan kinerja tugas NLP.

Pada tahun 2018, BERT (Bidirectional Encoder Representations from Transformers) diperkenalkan, menggunakan pendekatan pre-training dengan Masked Language Model (MLM) dan Next Sentence Prediction (NSP). Ini merevolusi NLP dengan menunjukkan efektivitas model pre-training pada korpora besar untuk mempelajari embedding kata yang terkontekstualisasi.

Seri GPT (Generative Pretrained Transformer), yang dikembangkan antara tahun 2018 dan 2020, menggunakan arsitektur Transformer decoder-only dan autoregressive language modeling. Seri model ini telah signifikan memajukan bidang NLP, berkontribusi pada pengembangan sistem kecerdasan buatan yang lebih canggih.

## Bagaimana LLM Bekerja?

## Self-Attention

Self attention adalah sebutan untuk nilai atensi ketika nilai matriks query, kunci dan
nilai sama semua. Proses self attention dapat dianalogikan dengan pembaca yang se-
dang mencoba memahami arti dan konteks kata pada kalimat. Manfaat utama dari self
attention adalah membangun dan memperkuat konteks kata pada kalimat.

Sebagai contoh, katakanlah terdapat kalimat "The animal didnâ€™t cross the street beccuase it was
too tired. Self attention memberikan bobot yang lebih tinggi untuk kata "animal" saat
memproses kata "it" karena kata "it" merujuk pada kata "animal", bukan kata "street"
ataupun objek lain



### Wording Embedding

Word Embedding layer mengubah kata menjadi vektor embedding, yaitu vektor yang dapat merepresentasikan arti relatif kata. Semakin kuat hubungan antara dua kata, maka vektor embeddingnya akan terletak semakin dekat pada ruang embedding. Setiap dimensi pada vektor embedding menyatakan korelasi kata dengan suatu atribut. Konsekuensinya, dapat dilakukan operasi aritmatika pada vektor embedding yang mengaproksimasi arti kata.

### Positional Encoding

Positional Encoding layer menyimpan informasi urutan atau posisi kata pada dokumen
dengan menambahkan vektor PE pada vektor embedding dari kata tersebut. Berikut
adalah rumus untuk vektor PE

### Multi-Head Attention

Multi-Head Attention melakukan perhitungan nilai atensi menggunakan banyak kepalaatau heads untuk memproses informasi pada subruang representasi yang berbeda.subruang representasi yang berbeda diperoleh dengan mengalikan matriks proyeksi atau menggunakan Linear layer tanpa bias pada matriks query, kunci, dan nilai. Nilai atensi yang telah diperoleh pada subruang representasi yang berbeda akan digabungkan dan diproyeksikan kembali pada ruang representasi awal menggunakan Concat layer dan Linear layer.

### Feed Forward Network

Feed forward network merupakan model ANN yang paling simpel. Feed forward network terdiri dari banyak simpul yang dibagi ke dalam 3 lapisan, yaitu Input layer, Hidden layer, dan Output layer. Setiap simpul terhubung dengan setiap simpul di layer
selanjutnya dengan suatu bobot. output dari Multi-Head Attention akan diproses oleh Feed Forward Network untuk menghasilkan output akhir.

Selanjutnya, model transformers akan dilatih. tipe pelatihan ayng dilakukan pada model ini terdapat dua, yaitu pretrain-training dan fine-tuning.

pretrain-training: Model dilatih pada korpus data teks yang besar. Memprediksi kata berikutnya dalam sebuah kalimat membantu model mempelajari tata bahasa, sintaksis, dan pemahaman bahasa secara umum.

Fine-tuning: Model disesuaikan pada tugas-tugas tertentu menggunakan dataset yang lebih kecil dan khusus untuk tugas tersebut. Proses ini membantu model mengkhususkan diri dalam berbagai aplikasi seperti pembuatan teks, terjemahan, jawaban pertanyaan, dan lain-lain.

## LLM For health care

Bagian Ini Membahas Aplikasi LLM pada Bidang Kesehatan dan Perawatan Kesehatan.

Large Language Models (LLMs) memiliki berbagai aplikasi dalam berbagai bidang, termasuk kesehatan. Salah satu manfaat paling signifikan dari LLM dalam kesehatan adalah deteksi dini penyakit. Dengan menganalisis catatan medis dan gambar, LLM dapat memberikan diagnosis yang lebih cepat dan akurat, serta rekomendasi pengobatan yang disesuaikan berdasarkan riwayat pasien. LLM juga dapat mengotomatisasi pekerjaan administratif dan entri data, menyederhanakan operasi di fasilitas kesehatan. Selain itu, LLM dapat digunakan untuk memberikan rekomendasi pengobatan yang dipersonalisasi berdasarkan riwayat pasien, mengotomatisasi tugas administratif seperti entri data, penjadwalan, dan penagihan, dan meningkatkan keterlibatan dan pendidikan pasien dengan memberikan rekomendasi yang dipersonalisasi untuk pasien berdasarkan riwayat medis dan preferensi mereka. Asisten kesehatan virtual yang didukung oleh LLM dapat meningkatkan komunikasi dan pendidikan untuk pasien, akhirnya mengarah pada hasil kesehatan yang lebih baik.








